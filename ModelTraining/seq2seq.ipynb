{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d4e904c",
   "metadata": {},
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d44512f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a20de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('udc_dataset_no_duplicate_titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24c3b7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uid', 'text', ' udc_1', ' udc_2', ' udc_3', ' udc_4', ' udc_5', 'type',\n",
       "       'generated_title', 'desc_custom_id', 'generated_description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f72404ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_list = df.copy()\n",
    "df_label_list['labels'] = df_label_list[' udc_1']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5bbfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>text</th>\n",
       "      <th>udc_1</th>\n",
       "      <th>udc_2</th>\n",
       "      <th>udc_3</th>\n",
       "      <th>udc_4</th>\n",
       "      <th>udc_5</th>\n",
       "      <th>type</th>\n",
       "      <th>generated_title</th>\n",
       "      <th>desc_custom_id</th>\n",
       "      <th>generated_description</th>\n",
       "      <th>labels</th>\n",
       "      <th>text_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A Beida</td>\n",
       "      <td>1¢(533.22)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>book</td>\n",
       "      <td>Exploring Contemporary Philosophies at Beida</td>\n",
       "      <td>0-request-book-0</td>\n",
       "      <td>\"Exploring Contemporary Philosophies at Beida\"...</td>\n",
       "      <td>1¢(533.22)</td>\n",
       "      <td>Exploring Contemporary Philosophies at Beida \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A Beida</td>\n",
       "      <td>1¢(533.22)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>book</td>\n",
       "      <td>Exploring Chinese Culture in Modern Times</td>\n",
       "      <td>0-request-book-1</td>\n",
       "      <td>\"Exploring Chinese Culture in Modern Times\" of...</td>\n",
       "      <td>1¢(533.22)</td>\n",
       "      <td>Exploring Chinese Culture in Modern Times \"Exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>A Beida</td>\n",
       "      <td>1¢(533.22)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>book</td>\n",
       "      <td>Whispers of the Old Library</td>\n",
       "      <td>0-request-book-2</td>\n",
       "      <td>In \"Whispers of the Old Library,\" A Beida weav...</td>\n",
       "      <td>1¢(533.22)</td>\n",
       "      <td>Whispers of the Old Library In \"Whispers of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A Beida</td>\n",
       "      <td>1¢(533.22)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>book</td>\n",
       "      <td>Whispers of the Eastern Lotus</td>\n",
       "      <td>0-request-book-3</td>\n",
       "      <td>\"Whispers of the Eastern Lotus\" is a captivati...</td>\n",
       "      <td>1¢(533.22)</td>\n",
       "      <td>Whispers of the Eastern Lotus \"Whispers of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>A Beida</td>\n",
       "      <td>1¢(533.22)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>article</td>\n",
       "      <td>Investigating the Differential Genetic Express...</td>\n",
       "      <td>0-request-sci-0</td>\n",
       "      <td>This article explores the variations in geneti...</td>\n",
       "      <td>1¢(533.22)</td>\n",
       "      <td>Investigating the Differential Genetic Express...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid     text       udc_1  udc_2  udc_3  udc_4   udc_5     type  \\\n",
       "0    0  A Beida  1¢(533.22)    NaN    NaN    NaN     NaN     book   \n",
       "1    0  A Beida  1¢(533.22)    NaN    NaN    NaN     NaN     book   \n",
       "2    0  A Beida  1¢(533.22)    NaN    NaN    NaN     NaN     book   \n",
       "3    0  A Beida  1¢(533.22)    NaN    NaN    NaN     NaN     book   \n",
       "4    0  A Beida  1¢(533.22)    NaN    NaN    NaN     NaN  article   \n",
       "\n",
       "                                     generated_title    desc_custom_id  \\\n",
       "0       Exploring Contemporary Philosophies at Beida  0-request-book-0   \n",
       "1          Exploring Chinese Culture in Modern Times  0-request-book-1   \n",
       "2                        Whispers of the Old Library  0-request-book-2   \n",
       "3                      Whispers of the Eastern Lotus  0-request-book-3   \n",
       "4  Investigating the Differential Genetic Express...   0-request-sci-0   \n",
       "\n",
       "                               generated_description      labels  \\\n",
       "0  \"Exploring Contemporary Philosophies at Beida\"...  1¢(533.22)   \n",
       "1  \"Exploring Chinese Culture in Modern Times\" of...  1¢(533.22)   \n",
       "2  In \"Whispers of the Old Library,\" A Beida weav...  1¢(533.22)   \n",
       "3  \"Whispers of the Eastern Lotus\" is a captivati...  1¢(533.22)   \n",
       "4  This article explores the variations in geneti...  1¢(533.22)   \n",
       "\n",
       "                                           text_desc  \n",
       "0  Exploring Contemporary Philosophies at Beida \"...  \n",
       "1  Exploring Chinese Culture in Modern Times \"Exp...  \n",
       "2  Whispers of the Old Library In \"Whispers of th...  \n",
       "3  Whispers of the Eastern Lotus \"Whispers of the...  \n",
       "4  Investigating the Differential Genetic Express...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_desc_combined = df_label_list.copy()\n",
    "df_text_desc_combined['text_desc'] = df_text_desc_combined['generated_title'].fillna('') + ' ' + df_text_desc_combined['generated_description'].fillna('')\n",
    "df_text_desc_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7a28ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_desc</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exploring Contemporary Philosophies at Beida \"...</td>\n",
       "      <td>1¢(533.22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exploring Chinese Culture in Modern Times \"Exp...</td>\n",
       "      <td>1¢(533.22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whispers of the Old Library In \"Whispers of th...</td>\n",
       "      <td>1¢(533.22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whispers of the Eastern Lotus \"Whispers of the...</td>\n",
       "      <td>1¢(533.22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Investigating the Differential Genetic Express...</td>\n",
       "      <td>1¢(533.22)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_desc      labels\n",
       "0  Exploring Contemporary Philosophies at Beida \"...  1¢(533.22)\n",
       "1  Exploring Chinese Culture in Modern Times \"Exp...  1¢(533.22)\n",
       "2  Whispers of the Old Library In \"Whispers of th...  1¢(533.22)\n",
       "3  Whispers of the Eastern Lotus \"Whispers of the...  1¢(533.22)\n",
       "4  Investigating the Differential Genetic Express...  1¢(533.22)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pruned = df_text_desc_combined[['text_desc', 'labels']].copy()\n",
    "df_pruned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f7ebf8",
   "metadata": {},
   "source": [
    "## Preparing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afef4289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wrimp\\Documents\\UDC2\\.conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33086be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5774ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenizer, inputs, targets, max_length=512):\n",
    "        self.encodings = tokenizer(\n",
    "            inputs,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_length)\n",
    "        self.targets = tokenizer(\n",
    "            targets,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=32)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.targets['input_ids'][idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eff38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GenDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    inputs=df_pruned['text_desc'].tolist(),\n",
    "    targets=df_pruned['labels'].tolist(),\n",
    "    max_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a7ddb6",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f18d57aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 37373\n",
      "Train samples: 23918\n",
      "Validation samples: 5980\n",
      "Test samples: 7475\n"
     ]
    }
   ],
   "source": [
    "# For multi-label classification, we'll use a simpler approach\n",
    "# Since StratifiedShuffleSplit doesn't work well with multi-label data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Get the total number of samples\n",
    "total_samples = len(dataset)\n",
    "indices = np.arange(total_samples)\n",
    "\n",
    "# First split: 80% train+val, 20% test\n",
    "trainval_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "# Second split: from the 80%, take 80% for train and 20% for validation\n",
    "# This gives us 64% train, 16% val, 20% test\n",
    "train_idx, val_idx = train_test_split(trainval_idx, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Total samples: {total_samples}\")\n",
    "print(f\"Train samples: {len(train_idx)}\")\n",
    "print(f\"Validation samples: {len(val_idx)}\")\n",
    "print(f\"Test samples: {len(test_idx)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c78eb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 23918\n",
      "Validation dataset size: 5980\n",
      "Test dataset size: 7475\n"
     ]
    }
   ],
   "source": [
    "# Create subset datasets\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "val_dataset = Subset(dataset, val_idx)\n",
    "test_dataset = Subset(dataset, test_idx)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0834fa56",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae1039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "702c5275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU memory status:\n",
      "GPU Memory Allocated: 0.69 GB\n",
      "GPU Memory Cached: 2.53 GB\n"
     ]
    }
   ],
   "source": [
    "# GPU memory monitoring and optimization functions\n",
    "def print_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "        print(f\"GPU Memory Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "    else:\n",
    "        print(\"CUDA not available\")\n",
    "\n",
    "def clear_gpu_cache():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"GPU cache cleared\")\n",
    "\n",
    "# Print initial memory usage\n",
    "print(\"Initial GPU memory status:\")\n",
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9906ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    load_best_model_at_end=True,\n",
    "    predict_with_generate=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e78a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the trainer without early stopping first to avoid callback issues\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    processing_class=tokenizer\n",
    ")\n",
    "\n",
    "# A weird bug where the early stopping callback is not recognized\n",
    "# #early_stopping = EarlyStoppingCallback(early_stopping_patience=3)\n",
    "#trainer.add_callback(early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3686e25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "479d5b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59800' max='59800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59800/59800 3:38:34, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.777700</td>\n",
       "      <td>0.714141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.739000</td>\n",
       "      <td>0.686634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.723400</td>\n",
       "      <td>0.663166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.700800</td>\n",
       "      <td>0.643227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.676600</td>\n",
       "      <td>0.625965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.663300</td>\n",
       "      <td>0.611457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.635300</td>\n",
       "      <td>0.597258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.609200</td>\n",
       "      <td>0.586195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.608700</td>\n",
       "      <td>0.575529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.599200</td>\n",
       "      <td>0.568066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.598700</td>\n",
       "      <td>0.559579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.599900</td>\n",
       "      <td>0.555644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.606100</td>\n",
       "      <td>0.551353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.596700</td>\n",
       "      <td>0.548711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.565100</td>\n",
       "      <td>0.547739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=59800, training_loss=0.4869249179291486, metrics={'train_runtime': 13114.2668, 'train_samples_per_second': 36.476, 'train_steps_per_second': 4.56, 'total_flos': 4.767143215890432e+16, 'train_loss': 0.4869249179291486, 'epoch': 20.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d45587e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./seq2seq_unpruned/udc_model_small\\\\tokenizer_config.json',\n",
       " './seq2seq_unpruned/udc_model_small\\\\special_tokens_map.json',\n",
       " './seq2seq_unpruned/udc_model_small\\\\tokenizer.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./seq2seq_unpruned/udc_model_small')\n",
    "tokenizer.save_pretrained('./seq2seq_unpruned/udc_model_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa624f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
